
---
title: "PADP8120 Midterm Fall 2015"
author: "Victoria Coxon"
output:
  html_document:
    highlight: pygments
    theme: cerulean
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
---


# Midterm Exam

**due by class time (3:35) on October 14, 2015**

## Instructions

A. Fork the [Midterm repository](https://github.com/PADP8120-Fall2015/Midterm) from the course github page to your github account (i.e., just as you would with a homework assignment)

B. In RStudio, create a new project and link it to your newly forked github repo. 

C. Resave the `Midterm_Fall2015.Rmd` file as `Midterm_Fall2015_FirstInitialLastName.Rmd` (e.g., `Midterm_Fall2015_TScott.Rmd`)

D. Complete the midterm within your `Midterm_Fall2015_FirstInitialLastName.Rmd` file. 

E. Make sure your final document renders as an `.html` file. 

F. Please **email** to me all of the materials necessary for another person to run your R Markdown file, including:
  - The R project (`.Rproj`) file
	- The R Markdown document (`.Rmd`) of your analyses
	- An HTML document (`.html`) compiled from your R Markdown document.
	- Any data or other files neede to run the analyses in your R Markdown document.

## Guidelines 

i. This is a take-home, open-book exam. This means that you are welcome to use any resources at your disposal--including textbooks, R help files, and internet resources--EXCEPTING other students (see Guideline #2).  

ii. However, you are expected to work alone, meaning that this exam **must not** be done as a group project or in concert with your classmates (or with the assistant of other SPIA students/faculty). The work you submit is to be yours and yours alone.

iii. Your exam write-up should be clear and legible, with answers clearly indicated and work shown. Your exam must be produced in html (.html) document produced using R Markdown (i.e., an .Rmd file). Submit both your .html file and the .Rmd file used to generate it via github to the course midterm repo. If you are having trouble accomplishing this, please refer to the [guide](http://spia.uga.edu/faculty_pages/tyler.scott/teaching/PADP8120_Fall2015/Homeworks/submitting_homework.shtml). 

iv. The exam will be graded out of 100 points. Each problem is worth a designated number of points (shown below). Partial credit *may* by given for incorrect answers if I am able to see the process by which you went wrong (and thus see what you also did correctly), so it is to your advantage to show your work. 

v. Your exam is **due by class time (3:35) on October 14, 2015**

vi. Please contact me if you have any questions or concerns.

# Problems

You are asked to analyze data from a New York City school voucher experiment that a colleague and I obtained from Mathematica for a paper. 

```{r eval=TRUE}
nyc = read.csv("C:/Users/Victoria/Desktop/PADP 8120/Midterm_Fall2015_VCoxon/input/NYC_SchoolVoucher_Experiment.csv",row.names=1)
str(nyc)
nyc<-read.table("C:/Users/Victoria/Desktop/PADP 8120/Midterm_Fall2015_VCoxon/input/NYC_SchoolVoucher_Experiment.csv", sep=",", header=T)
head(nyc)
```
There are 2666 observations of 18 variables.

Most of the variables you need should be pretty self explanatory:

| Variable | Description |
|:---|:---|
| `Student_ID` | numerical code for each student |
| `Family_ID` | numerical code for each family |
| `Date.Of.Birth` | student birthday |
| `Female` | binary indicator for female students; 1 = female, 0 = male |
| `Grade`   |  student grade level when starting experiment |
| `Treatment`    |  binary indicator for whether student received voucher; 1 = Voucher Treatment, 0 = No Voucher |
| `Latino`  |   binary indicator for Latino students; 1 = Latino, 0 = Otherwise |
| `Black` |   binary indicator for black students; 1 = Black, 0 = Otherwise |
| `Eldest` |   binary indicator for eldest children; 1 = Eldest, 0 = Otherwise |
| `y0_read_percentile`   |  pre-test reading score percentile |
| `y0_math_percentile`    |  pre-test math score percentile |
| `y1_read_percentile`   |  reading score percentile after 1y |
| `y1_math_percentile`    |  math score percentile after 1y |
| `y2_read_percentile`   |  reading score percentile after 2y |
| `y2_math_percentile`    |  math score percentile after 2y |
| `y3_read_percentile`   |  reading score percentile after 3y |
| `y3_math_percentile`    |  math score percentile after 3y |

1. (6 points) Compute the average reading and math percentiles for each year across all students. 

```{r}
library(dplyr)
library(ggplot2)
library(pastecs)

attach(nyc)
scores <- cbind(y0_read_percentile, y0_math_percentile, y1_read_percentile, y1_math_percentile, y2_read_percentile, y2_math_percentile, y3_read_percentile, y3_math_percentile)
stat.desc(scores)

options(scipen=100)
stat.desc(scores)

stat.desc(scores, basic=F)

# Method adapted from http://www.ats.ucla.edu/stat/r/faq/basic_desc.htm 
```
The mean scores for reading and mathematics are as follows:
Reading Year 0 = 22.78          Mathematics Year 0 = 16.54 
Reading Year 1 = 26.06          Mathematics Year 1 = 22.30
Reading Year 2 = 26.09          Mathematics Year 2 = 23.56
Reading Year 3 = 32.63          Mathematics Year 3 = 32.50

2. (4 points) Clean the original dataset by removing all students who do not have observed pre-test scores and year 1 scores for reading and for math.

```{r}
stat.desc(scores, desc=F)
# x <- airquality[complete.cases(airquality), ]
clean.nyc <- filter(nyc, y0_read_percentile!='NA', y0_math_percentile!='NA', y1_read_percentile!='NA', y1_math_percentile!='NA')
str(clean.nyc)              
head(clean.nyc)

attach(clean.nyc)
clean.scores <- cbind(y0_read_percentile, y0_math_percentile, y1_read_percentile, y1_math_percentile, y2_read_percentile, y2_math_percentile, y3_read_percentile, y3_math_percentile)
stat.desc(scores)

options(scipen=100)
stat.desc(clean.scores)

stat.desc(clean.scores, basic=F)
```
I cleaned the data and then checked to see if there was a dfference in the summary statistics based on the scores from the cleaned data. There is a difference, as would be expected when missing observations are dropped. Dropping observations with missing values effectively lowered the sample size from 2666 observations to 1455 observations.We might want to be a little more cautious in any inferences we make from this data.
Reading Year 0 = 22.78; Clean = 22.57          Mathematics Year 0 = 16.54; Clean = 16.42  
Reading Year 1 = 26.06; Clean = 24.63          Mathematics Year 1 = 22.30; Clean = 23.24
Reading Year 2 = 26.09; Clean = 25.26          Mathematics Year 2 = 23.56; Clean = 24.24 
Reading Year 3 = 32.63; Clean = 33.54          Mathematics Year 3 = 32.50; Clean = 33.23

3. (8 points) Make a figure (either a density plot of a histgram format) comparing the distributions of percentile reading scores for students who did and did not receive a voucher. Do your best to make the figure "publishable" by giving it clear axis titles, legend labels, and other aesthetic improvements. 

```{r}
no.vouch <- filter(clean.nyc,Treatment=="1")
vouch <- filter(clean.nyc,Treatment=="0")
qplot(no.vouch$y0_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 0 Reading Scores - No Voucher", xlab = "Reading Percentile Scores", fill=I("blue"))
qplot(vouch$y0_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 0 Reading Scores - Voucher", xlab = "Reading Percentile Scores", fill=I("darkgreen"))
qplot(no.vouch$y1_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 1 Reading Scores - No Voucher", xlab = "Reading Percentile Scores", fill=I("blue"))
qplot(vouch$y1_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 1 Reading Scores - Voucher", xlab = "Reading Percentile Scores", fill=I("darkgreen"))
qplot(no.vouch$y2_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 2 Reading Scores - No Voucher", xlab = "Reading Percentile Scores", fill=I("blue"))
qplot(vouch$y2_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 2 Reading Scores - Voucher", xlab = "Reading Percentile Scores", fill=I("darkgreen"))
qplot(no.vouch$y3_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 3 Reading Scores - No Voucher", xlab = "Reading Percentile Scores", fill=I("blue"))
qplot(vouch$y3_read_percentile,geom = "histogram", binwidth = 1.0, main = "Year 3 Reading Scores - Voucher", xlab = "Reading Percentile Scores", fill=I("darkgreen"))

ggplot(data = no.vouch) + geom_density(aes(x = y0_read_percentile), main = "Year 0 Reading Scores - No Voucher", xlab = "Reading Percentile Scores",fill = "blue")
ggplot(data = vouch) + geom_density(aes(x = y0_read_percentile),main = "Year 0 Reading Scores - Voucher",xlab = "Reading Percentile Scores",fill="darkgreen" )
ggplot(data = no.vouch) + geom_density(aes(x = y1_read_percentile), main = "Year 1 Reading Scores - No Voucher", xlab = "Reading Percentile Scores",fill = "blue")
ggplot(data = vouch) + geom_density(aes(x = y1_read_percentile),main = "Year 1 Reading Scores - Voucher",xlab = "Reading Percentile Scores",fill="darkgreen")
ggplot(data = no.vouch) + geom_density(aes(x = y2_read_percentile), main = "Year 2 Reading Scores - No Voucher", xlab = "Reading Percentile Scores",fill = "blue")
ggplot(data = vouch) + geom_density(aes(x = y2_read_percentile),main = "Year 2 Reading Scores - Voucher",xlab = "Reading Percentile Scores",fill="darkgreen")
ggplot(data = no.vouch) + geom_density(aes(x = y3_read_percentile), main = "Year 3 Reading Scores - No Voucher", xlab = "Reading Percentile Scores",fill = "blue")
ggplot(data = vouch) + geom_density(aes(x = y3_read_percentile),main = "Year 3 Reading Scores - Voucher",xlab = "Reading Percentile Scores",fill="darkgreen")
```

4. (4 points) In no more than 2-3 sentences, describe what your visualization in 1.C indicates about these data. Do the treatment and control groups appear to be similar (in terms of reading pre-test scores)? Why or why not? 
```{r}
summary(vouch$y0_read_percentile)
summary(no.vouch$y0_read_percentile)
```
Looking at both density plots, histograms, and summary statstics for pre-test reading scores of the *cleaned* data it appears that the groups are similar despite slightly higher dispersion in the no.voucher set. Despite this, they appear to be a good match for isolating the effect of the voucher using test scores (even though we are not necessarily discussing causality at this point). Additionally, this comparability appears to hold for years 1, 2, and 3.  

5. (4 points) Typically, policy experiments such as the NYC school voucher lottery experiment are indended to produce statistical evidence that can then be generalized to broader policy applications (i.e., how might vouchers influence educational outcomes for other students who weren't part of the original experiment). Based on the reading pre-test scores that you visualized in C, describe any concerns you might have about our ability to generalize the results of this experiment to ALL elementary school students in the United States in no more than 2-3 sentences. 

When I cleaned the data, I dropped 1,211 observations which is close to half of the original sample and may not be enough observations to meet the required test power. This would compromise the external validity/generalizability of the statistical conclusions. Additionally, there may be some other attribute, such as "goodness of fit" with the school culture or the broader community, that is not included in this model that could account for some of the change in scores other than the voucher. Children who do not "fit" or cannot continue for any other reason may change schools after the first year; these observations got dropped when I cleaned the data.

6. (4 points) What is the probability that a randomly selected student in the dataset received a voucher and scored above the 50th percentile on the math pre-test?
```{r}
table(nyc$Treatment)
nyc.pvouch0 = 1292/2666
nyc.vouch1 = 1374/2666
nyc.vouch1
#Probability of receiving a voucher is 0.52; 1-p = 0.48
summary(nyc$y0_math_percentile)

mean <- 16.5424095 
sd <- 19.4851214 
nyc.prob.51 <- pnorm(q=51, mean = mean, sd = sd, lower.tail = FALSE)
nyc.prob.51
# Probability of scoring above the 50%ile is 0.038 or 3.6 %.

nyc.vouch.mean <- mean(vouch$y0_math_percentile)
nyc.vouch.sd <- sd(vouch$y0_math_percentile)
nyc.vouch1 <- pnorm(q=51, mean = nyc.vouch.mean, sd = nyc.vouch.sd, lower.tail = FALSE)

nyc.prob.vouch.51 = nyc.vouch1 * nyc.prob.51
nyc.prob.vouch.51
```
The probability that a randomly selected student in the dataset received a voucher and scored above the 50th percentile on the math pre-test is 0.001425803. 

7. (4 points) What is the probability that a randomly selected student who received a voucher group scored above the 50th percentile on the math pre-test?
```{r}
table(clean.nyc$Treatment)
clean.nyc.pvouch0 = 674/1455
clean.nyc.vouch1 = 781/1455
clean.nyc.vouch1
#Probability of receiving a voucher is 0.51; 1-p = 0.49
summary(clean.nyc$y0_math_percentile)

clean.mean <- mean(clean.nyc$y0_math_percentile)
clean.sd <- sd(clean.nyc$y0_math_percentile)
prob.51 <- pnorm(q=51, mean = clean.mean, sd = clean.sd, lower.tail = FALSE)
# Probability of scoring above the 50%ile is 0.036 or 3.6 %.

vouch.mean <- mean(vouch$y0_math_percentile)
vouch.sd <- sd(vouch$y0_math_percentile)
pnorm(q=51, mean = vouch.mean, sd = vouch.sd, lower.tail = FALSE)

prob.vouch.51 = clean.nyc.vouch1 * prob.51
prob.vouch.51
```
The probability that a randomly selected student who received a voucher group scored above the 50th percentile on the math pre-test is 0.01927126.


8. (4 points) We are interested in studying whether the change in math scores after one year is different for students who receive a voucher versus those who do not. Write the null and alternative hypotheses in words and then using symbols.

9. (6 points) Evaluate the hypothesis from 1.H at a significance level of $\alpha = 0.05$ and state your conclusion in 1-2 sentences. 

10. (2 points) Would your conclusion change at $\alpha = 0.10$? Why or why not?

11. (6 points) There are four assumptions that hold for the test above to be valid: independence within groups, independence between groups, sample sizes both above 30, and symmetric distributions. Are you satisfied that each of these are upheld? Is there anything in particular that you might be concerned about? 

12. (4 points) Next, you are asked to evaluate whether students in the treatment group differ in terms of their reading ability from the pre-test to the year 1 post-test. Write out the null and alternative hypotheses in words and then in symbols. 

13. (6 points) Conduct a t-test to evaluate this hypothesis at $\alpha = 0.01$ significance level. Interpret your results in 1-2 complete sentences.  
 
14. (4 points) Explain how you could evaluate the hypothesis above using a confidence interval instead of a p-value.

15. (2 points) Interpret the confidence interval you estimated for question N in a sentence.

16. (8 points) Perform a test of whether the average math pre-test score differs by grade level at $\alpha = 0.10$ significance level. Write out your hypothesis in symbols, perform the test, and then report your findings in a complete sentence.

17. (8 points) The NYC School District considers students who perform at or above the 50th percentile to be "passing". At a 99% significance level, is the proportion of all students in the sample (voucher and no-voucher) that are considered to be passing in math significantly different between the pre-test and year 1 post-test?

18. (6 points) Make a boxplot that compares the distribution of math scores between the pre-test and year 1 post-test for all students. Do your best to make the figure "publishable" by giving it clear axis titles, legend labels, and other aesthetic improvements. In no more than 2-3 sentences, describe how your figure supports (or does not support) your finding from question 17.

19. (4 points) Consider the correlation between math percentile and reading percentile for year 1 test scores. Compute Pearson’s `r` between these two variables. Is the correlation higher or lower than you would have expected? 

20. (6 points) You might argue that percentiles are actually rank-order data and not ratio-level data. For rank-order data, a more appropriate correlation measure is Spearman’s $\rho$, which is a rank correlation. Compute $\rho$ and contrast the results from $r$ (for question S above). Why do the results differ?

